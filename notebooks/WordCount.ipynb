{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCount Example\n",
    "\n",
    "In this example we'll be using the Back to the Future transcript which is formatted as `Character: Line`. For example:\n",
    "\n",
    "`Doc: Marty, is that you?`\n",
    "\n",
    "In the first part we'll count the number of words in the transcript (we'll filter out the character names) and sort them by most frequently used to least frequently used.\n",
    "\n",
    "In the second part we'll filter out common words, known as stop words, by importing a Python package using pip. \n",
    "\n",
    "Finally, we'll find the most common words used by each character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Simple Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the regular expression package\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the transcript using SparkContext.textFile\n",
    "# This will return an RDD of strings - one for each line in the transcript \n",
    "lines = sc.textFile(\"file:///usr/data/backtothefuture_transcript.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will be called for each line in the transcript\n",
    "# We will strip out the character names (i.e. Marty:)\n",
    "# We'll also strip out special characters in each string\n",
    "# Finally, we'll return an array of words\n",
    "def parseLine(line):\n",
    "    line = re.sub(\"^[^:]+:\", \"\", line)\n",
    "    line = re.sub(\"[^a-zA-Z ']\", \"\", line)\n",
    "    lineWords = re.split(\"\\s+\", line.lower())\n",
    "    return filter(lambda w: w not in \"\", lineWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatMap can map each input to 0 or more outputs\n",
    "# In this case each line of text will be mapped to 0 or more words\n",
    "words = lines.flatMap(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map each RDD to (key, 1) where key is the word\n",
    "wordCounts = words.map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduceByKey takes 2 RDDs with the same key, combines them into a single RDD,\n",
    "# and sets the value to the output of the lambda function\n",
    "# In this case that value is x + y giving us the total count for each word (the key)\n",
    "wordCounts = wordCounts.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we reverse the RDDs, so instead of (word, count)\n",
    "# They will be stored as (count, word)\n",
    "# This will allow us to sort by the key (count)\n",
    "wordCountsReversed = wordCounts.map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by key (which is now count) descending\n",
    "wordCountsSorted = wordCountsReversed.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 words\n",
    "wordCountsSorted.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Filter Out Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the stop-words package\n",
    "!pip3 install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the stop_words package (note the underscore)\n",
    "import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In addition to stripping out character names and special characters\n",
    "# this time we also strip out stop words\n",
    "def parseLine2(line):\n",
    "    line = re.sub(\"^[^:]+:\", \"\", line)\n",
    "    line = re.sub(\"[^a-zA-Z ']\", \"\", line)\n",
    "    lineWords = re.split(\"\\s+\", line.lower())\n",
    "    lineWords = filter(lambda w: w not in \"\", lineWords)\n",
    "    stopWords = stop_words.get_stop_words('en')\n",
    "    return filter(lambda w: w not in stopWords, lineWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the words from the lines\n",
    "words = lines.flatMap(parseLine2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map and reduce by key to get total word counts\n",
    "wordCounts = words.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse and sort by key (count) descending\n",
    "wordCountsSorted = wordCounts.map(lambda x: (x[1], x[0])).sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 words - not including stop words\n",
    "wordCountsSorted.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Word Counts by Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire contents of the file, so we can group words by character\n",
    "# wholeTextFiles returns an RDD formatted as (fileName, fileContents)\n",
    "contents = sc.wholeTextFiles(\"file:///usr/data/backtothefuture_transcript.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to group words by character we need to parse the entire contents\n",
    "# of the transcript at once. This way we can keep track of the last character specified\n",
    "# as we handle each new line (some new lines won't specify a character)\n",
    "def parseContents(contents):\n",
    "    regex = r'(^[a-z^:]+:)'\n",
    "    strs = re.compile(regex, re.UNICODE|re.MULTILINE).split(contents.lower())\n",
    "    key = None\n",
    "    tuples = []\n",
    "    for str in strs:\n",
    "        if re.match(regex, str) is not None:\n",
    "            key = str[:-1] # get rid of the ending colon\n",
    "        elif key is not None:\n",
    "            words = parseLine2(str)\n",
    "            for word in words:\n",
    "                tuples.append((key, word))\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the contents of the text file\n",
    "# No Spark magic here - just using Python to create a list of (character, word) tuples\n",
    "characterWordTuples = parseContents(contents.values().take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use SparkContext.parallelize to convert the list of tuples to RDDs\n",
    "characterWords = sc.parallelize(characterWordTuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at a few of them\n",
    "characterWords.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similarly to how we did our generic word count we are going to\n",
    "# map each RDD to (key, 1) where key is the (character, word) tuple\n",
    "characterWordCounts = characterWords.map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll reduce by key the same way we did before\n",
    "characterWordCounts = characterWordCounts.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our RDDs look like now\n",
    "characterWordCounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse the RDDs, so we can sort by count as the key\n",
    "characterWordCountsReversed = characterWordCounts.map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by count descending\n",
    "characterWordCountsSorted = characterWordCountsReversed.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 caracter/word combinations and display them\n",
    "characterWordCountsSorted.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What we really want is the top word for each character, not the top character/word combinations\n",
    "# We'll start by making the character the key\n",
    "# We'll map the RDD above (count, (character, word)) to (character, (word, count)) \n",
    "characterWordCounts2 = characterWordCountsSorted.map(lambda x: (x[1][0], (x[1][1],x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what it looks like\n",
    "characterWordCounts2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, we'll reduceByKey, but this time we won't add the values\n",
    "# We'll take the (word, count) tuple that has the highest count\n",
    "characterWordCounts2 = characterWordCounts2.reduceByKey(lambda x, y: (x if x[1] > y[1] else y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's restructure the RDDs, so we can sort by the characters with the most words\n",
    "characterWordCounts2Reversed = characterWordCounts2.map(lambda x: (x[1][1], (x[0],x[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by key (count) descending\n",
    "characterWordCounts2Sorted = characterWordCounts2Reversed.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally! Here are the top words for the 10 characters with the most lines\n",
    "characterWordCounts2Sorted.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spark 2.1.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
